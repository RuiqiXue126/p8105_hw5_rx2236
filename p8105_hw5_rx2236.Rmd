---
title: "p8105_hw5_rx2236"
author: "Ruiqi Xue"
date: "2023-11-12"
output: github_document
---


```{r, message=FALSE}
library(tibble)
library(tidyverse)
library(purrr)
library(broom)
library(ggplot2)
set.seed(1)
```

## Problem 2

Create a dataframe and read in the data iteratively.
```{r, message=FALSE, warning=FALSE}
p2_df = 
  tibble(
    file_name = list.files("data/")
    ) |>
  mutate(data = map(str_c("data/", file_name), read_csv)) |>
  unnest()

```

Tidy the dataframe.
```{r}
p2_df = p2_df |>
  mutate(file_name = str_replace(file_name, ".csv", ""),
         arm = str_sub(file_name, 1, 3),
         id = str_sub(file_name, 5, 7)) |>
  pivot_longer(week_1:week_8,
               names_to = "week",
               values_to = "observation",
               names_prefix = "week_") |>
  mutate(week = as.numeric(week),
         arm = case_match(
           arm,
           "con" ~ "control",
           "exp" ~ "experimental"
         )) |>
  select(arm, id, week, observation)

p2_df
  
```

Make a spaghetti plot showing observations on each subject over time.

```{r}
p2_df |>
  group_by(arm, id) |>
  ggplot(aes(x = week, y = observation, color = id)) +
  geom_line(alpha = 0.8) +
  facet_grid(~arm) +
  geom_smooth(aes(group = 1), se = FALSE, color = "black") +
  labs(x = 'Week', y = 'Observation', title = 'Plot of Observations on Subjects in Each Arm Over Time')
```

Compare the two arms, we see that values in the control arm fluctuate placidly over time, whereas values in the experimental arm are higher than the ones in the control arm in general, and have an increasing tendency over time.


## Problem 3

Set mu = 0,simulate 5000 datasets.
```{r}

sim_t_test = function(mu = mu, n = 30, sigma = 5) {
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)
    )
  sim_result = broom::tidy(t.test(sim_data))
  sim_result |> 
    select(estimate, p.value)
    
}

sim_results_df = expand_grid(
  mu = 0,
  iter = 1:5000) |>
  mutate(estimate_df = map(mu, sim_t_test)) |> 
  unnest(estimate_df) |>
  rename("mu_estimate" = estimate) |>
  rename("p_value" = "p.value")
  

sim_results_df
```


Repeat the above procedure for mu = {1,2,3,4,5,6}.

```{r}
sim_result_df2 = 
  expand_grid(
    mu = c(1, 2, 3, 4, 5, 6),
    iter = 1:5000) |> 
  mutate(estimate_df = map(mu, sim_t_test)) |> 
  unnest(estimate_df) |>
  rename("mu_estimate" = estimate) |>
  rename("p_value" = "p.value")



```

Making plots.

First we make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. 
```{r}
sim_result_df2 |>
  group_by(mu) |>
  summarize(reject_count = sum(p_value <= 0.05), total_count = n(), power = reject_count / total_count) |>
  #power = mean(p_value <= 0.05)
  ggplot(aes(x = mu, y = power)) + 
  geom_point() + geom_line() +
  scale_x_continuous(labels = scales::number_format(prefix = "mu = "), breaks = seq(0,6,1)) +
  labs(x = "True value of the mean", y = "Power of the test", title = "Power of the One-Sample T-test on Different True Values of the Mean")
```
We can see that the association between effect size (i.e., difference in true mean and null hypothesis mean) and power is positive, that the larger the true value of mean, the larger the effect size, the higher the power of the test.  


Second we make a plot showing the average estimate of μ̂ on the y axis and the true value of μ on the x axis.
```{r}
sim_result_df2 |>
  group_by(mu) |>
  summarize(average_estimate = mean(mu_estimate)) |>
  ggplot(aes(x = mu, y = average_estimate)) + 
  geom_point() + geom_line() +
  scale_x_continuous(labels = scales::number_format(prefix = "mu = "), breaks = seq(0,6,1)) +
  scale_y_continuous(breaks = seq(0,6,1)) +
  labs(x = "True value of the mean", y = "Average estimate of the mean", title = "Average Estimate of Mean in One-Sample T-test Given True Values of the Mean")
```
We can see that the sample average of estimated means across all tests is approximately equal to the true value of mean.


Then we make another plot showing the average estimate of μ̂ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. 
```{r}
sim_result_df2 |>
  filter(p_value <= 0.05) |>
  group_by(mu) |>
  summarize(average_estimate = mean(mu_estimate)) |>
  ggplot(aes(x = mu, y = average_estimate)) + 
  geom_point() + geom_line() +
  scale_x_continuous(labels = scales::number_format(prefix = "mu = "), breaks = seq(0,6,1)) +
  scale_y_continuous(breaks = seq(0,6,1)) +
  labs(x = "True value of the mean", y = "Average estimate of the mean", title = "Average Estimate of Mean Only in Samples for which the Null was Rejected Given True Values of the Mean")
```
```{r}
sim_result_df2 |>
  filter(p_value <= 0.05) |>
  group_by(mu) |>
  summarize(average_estimate = mean(mu_estimate))
```

From this graph, we see that the sample average of estimated means across tests for which the null is rejected is not approximately equal to the true value of mean, (although it tend to get closer as the true value of the mean increases). 
This is because we reject the null at an 0.05 significance level, meaning that there is a 5% probability that the null hypothesis is rejected when it is actually true (type I error). 
Therefore, the average of estimated means across tests where the null hypothesis is rejected may not be exactly equal to the true value of the sample mean.







